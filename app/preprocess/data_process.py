# app/preprocess/merge_hourly.py
from __future__ import annotations

import glob
import os
from pathlib import Path
from typing import Optional

import pandas as pd


def merge_and_compress_hourly(
    input_dir: Path,
    output_dir: Path,
    output_filename: str = "2025_merged_hour_all.csv",
) -> Path:
    """
    æŒ‡å®šãƒ•ã‚©ãƒ«ãƒ€å†…ã® CSV ã‚’ã™ã¹ã¦èª­ã¿è¾¼ã¿ã€
    2ç§’ãƒ‡ãƒ¼ã‚¿ â†’ 1æ™‚é–“å¹³å‡ã«åœ§ç¸®ã—ã¦çµåˆã—ãŸ CSV ã‚’å‡ºåŠ›ã™ã‚‹ã€‚

    Returns
    -------
    Path
        å‡ºåŠ›ã•ã‚ŒãŸ CSV ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    """
    input_dir = Path(input_dir)
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    # *.csv / *.CSV ã‚’ä¸¡æ–¹å¯¾è±¡ã«ã™ã‚‹
    all_files = sorted(
        glob.glob(str(input_dir / "*.csv")) + glob.glob(str(input_dir / "*.CSV"))
    )

    if not all_files:
        raise FileNotFoundError(f"{input_dir} å†…ã« CSV ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

    compressed_df_list: list[pd.DataFrame] = []

    for file in all_files:
        file_name = os.path.basename(file)
        try:
            df = pd.read_csv(file, encoding="shift_jis", skiprows=2, low_memory=False)

            # ä¸è¦åˆ—å‰Šé™¤ï¼ˆã‚ã‚Œã°ï¼‰
            drop_cols = [c for c in ["INDEX.1", "TIME.1"] if c in df.columns]
            if drop_cols:
                df = df.drop(columns=drop_cols)

            # å…¨ NaN åˆ—ã‚’å‰Šé™¤
            df = df.dropna(axis=1, how="all")

            if "TIME" not in df.columns:
                print(f"è­¦å‘Š: {file_name} ã« TIME åˆ—ãŒç„¡ã„ãŸã‚ã‚¹ã‚­ãƒƒãƒ—")
                continue

            df["TIME"] = pd.to_datetime(df["TIME"], errors="coerce")
            df = df.dropna(subset=["TIME"])

            if df.empty:
                print(f"è­¦å‘Š: TIME å¤‰æ›å¾Œã«ç©ºã«ãªã£ãŸãŸã‚ã‚¹ã‚­ãƒƒãƒ—: {file_name}")
                continue

            # 1æ™‚é–“ã”ã¨ã«ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆå¹³å‡ï¼‰
            df = df.set_index("TIME").resample("1H").mean(numeric_only=True).reset_index()

            if df.empty:
                print(f"è­¦å‘Š: resample å¾Œã«ç©ºã«ãªã£ãŸãŸã‚ã‚¹ã‚­ãƒƒãƒ—: {file_name}")
                continue

            compressed_df_list.append(df)
            print(f"å‡¦ç†å®Œäº†: {file_name}")

        except Exception as e:  # noqa: BLE001
            print(f"ã‚¨ãƒ©ãƒ¼: {file_name} - {e}")

    if not compressed_df_list:
        raise RuntimeError("æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒ 1 ã¤ã‚‚ç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")

    merged_df = pd.concat(compressed_df_list, ignore_index=True)
    merged_df = merged_df.sort_values("TIME").reset_index(drop=True)

    output_path = output_dir / output_filename
    merged_df.to_csv(output_path, index=False)
    print(f"å…¨ãƒ•ã‚¡ã‚¤ãƒ«çµåˆ: {output_path} ã«ä¿å­˜ã—ã¾ã—ãŸã€‚ğŸ‘")

    return output_path
